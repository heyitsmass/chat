id,description,name,image_url,provider
gemma2-9b-it,"Google's lightweight powerhouse that punches above its weight class. This instruction-tuned model balances efficiency with surprising capability, making it perfect for resource-constrained applications while still delivering impressive reasoning.",Gemma 2,,Google,
llama-3.3-70b-versatile,"Meta's flagship generalist model with exceptional adaptability across tasks. Known for its balance of creative writing, analytical reasoning, and code generation skills. The 'versatile' variant emphasizes flexibility for diverse use cases.",LLaMA 3.3,,Meta,
llama-3.1-8b-instant,"The speedster of Meta's lineup. Optimized for lightning-fast responses with minimal latency, it's perfect for real-time applications like chatbots and interactive tools where milliseconds matter.",LLaMA 3.1,,Meta
llama-guard-3-8b,"Meta's specialized safety bouncer. Designed specifically to detect and filter harmful content, this model serves as the ethical gatekeeper that helps larger models stay within appropriate boundaries.",LLaMA Guard 3,,Meta
llama3-70b-8192,"The memory elephant of Meta's models. With its extended 8192-token context window, it excels at tasks requiring understanding of lengthy documents and conversations while maintaining coherence throughout.",LLaMA 3 (70B),,Meta
llama3-8b-8192,"The compact but attentive model with surprising memory. Despite its smaller parameter count, it can process the same 8192-token context as its larger sibling, making it ideal for applications needing long-context understanding without massive compute.",LLaMA 3 (8B),,Meta
mixtral-8x7b-32768,"Mistral AI's Mixture of Experts architecture with a stunning 32K context window. This model dynamically activates different expert networks for different tasks, achieving remarkable performance efficiency while handling documents of novel-length.",Mixtral,,Mistral AI
meta-llama/llama-4-scout-17b-16e-instruct,"Meta's specialized reconnaissance model featuring 16 expert networks. Instruction-tuned to excel at information retrieval and analysis tasks, it's like having a research assistant with photographic memory and keen attention to detail.",LLaMA 4 Scout,,Meta
qwen-qwq-32b,"Alibaba's quirky but powerful model with particular strengths in multilingual capabilities and creative content generation. The unusual "QWQ" naming hints at its emotional intelligence and conversational fluency.",Qwen QWQ,,Alibaba
mistral-saba-24b,"Named after the warm Mediterranean wind, this mid-sized model from Mistral AI offers a refreshing balance of capabilities with exceptional instruction-following and reasoning abilities. Known for its reliable performance across diverse tasks.",Saba,,Mistral AI
qwen-2.5-32b,"Alibaba's refined general-purpose model representing a significant evolution in their architecture. Particularly adept at handling Asian languages alongside English, with impressive coding and mathematical reasoning capabilities.",Qwen 2.5,,Alibaba
deepseek-r1-distill-qwen-32b,"A knowledge-transfer marvel that captures the essence of Qwen's abilities in DeepSeek's architecture. This hybridization creates unique strengths in multilingual understanding while maintaining DeepSeek's renowned analytical capabilities.",R1 distilled by Qwen,,Deepseek
deepseek-r1-distill-llama-70b,"The heavyweight knowledge fusion of DeepSeek and LLaMA technologies. This model combines LLaMA's reasoning strength with DeepSeek's specialized training approach, creating a versatile powerhouse particularly skilled at complex problem-solving.",R1 distilled by LLaMA,,Deepseek